---
  title: "April 2024 II"
---

Date: **4PM Wednesday 24th April 2024**

Room: [Salle 08](../psc_rooms.qmd), [PariSant√© Campus](https://maps.app.goo.gl/cpFoxoZgbT6HCV6x9)

------------------------------------------------------------------------

### MCMC when you do not want to evaluate the target distribution

**Guanyang Wang** *Rutgers University*

In sampling tasks, it is common for target distributions to be known up to a normalizing constant. However, in many situations, evaluating even the unnormalized distribution can be costly or infeasible. This issue arises in scenarios such as sampling from the Bayesian posterior for large datasets and the 'doubly intractable' distributions. We provide a way to unify various MCMC algorithms, including several minibatch MCMC algorithms and the exchange algorithm. This framework not only simplifies the theoretical analysis of existing algorithms but also creates new algorithms. Similar frameworks exist in the literature, but they concentrate on different objectives.

::: callout-tip
## Special edition

[All About That Bayes](https://sites.google.com/view/all-about-that-bayes/home) and **Mostly Monte Carlo** joint seminar!
:::
